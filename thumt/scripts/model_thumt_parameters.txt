weights                                                        [42024, 1024]
encoder.layer_stack.0.self_attention.attention.q_transform.weight    [1024, 1024]
encoder.layer_stack.0.self_attention.attention.q_transform.bias          [1024]
encoder.layer_stack.0.self_attention.attention.k_transform.weight    [1024, 1024]
encoder.layer_stack.0.self_attention.attention.k_transform.bias          [1024]
encoder.layer_stack.0.self_attention.attention.v_transform.weight    [1024, 1024]
encoder.layer_stack.0.self_attention.attention.v_transform.bias          [1024]
encoder.layer_stack.0.self_attention.attention.o_transform.weight    [1024, 1024]
encoder.layer_stack.0.self_attention.attention.o_transform.bias          [1024]
encoder.layer_stack.0.self_attention.layer_norm.weight                [1024]
encoder.layer_stack.0.self_attention.layer_norm.bias                  [1024]
encoder.layer_stack.0.feed_forward.ffn_layer.input_transform.weight    [8192, 1024]
encoder.layer_stack.0.feed_forward.ffn_layer.input_transform.bias          [8192]
encoder.layer_stack.0.feed_forward.ffn_layer.output_transform.weight    [1024, 8192]
encoder.layer_stack.0.feed_forward.ffn_layer.output_transform.bias          [1024]
encoder.layer_stack.0.feed_forward.layer_norm.weight                  [1024]
encoder.layer_stack.0.feed_forward.layer_norm.bias                    [1024]
encoder.layer_stack.1.self_attention.attention.q_transform.weight    [1024, 1024]
encoder.layer_stack.1.self_attention.attention.q_transform.bias          [1024]
encoder.layer_stack.1.self_attention.attention.k_transform.weight    [1024, 1024]
encoder.layer_stack.1.self_attention.attention.k_transform.bias          [1024]
encoder.layer_stack.1.self_attention.attention.v_transform.weight    [1024, 1024]
encoder.layer_stack.1.self_attention.attention.v_transform.bias          [1024]
encoder.layer_stack.1.self_attention.attention.o_transform.weight    [1024, 1024]
encoder.layer_stack.1.self_attention.attention.o_transform.bias          [1024]
encoder.layer_stack.1.self_attention.layer_norm.weight                [1024]
encoder.layer_stack.1.self_attention.layer_norm.bias                  [1024]
encoder.layer_stack.1.feed_forward.ffn_layer.input_transform.weight    [8192, 1024]
encoder.layer_stack.1.feed_forward.ffn_layer.input_transform.bias          [8192]
encoder.layer_stack.1.feed_forward.ffn_layer.output_transform.weight    [1024, 8192]
encoder.layer_stack.1.feed_forward.ffn_layer.output_transform.bias          [1024]
encoder.layer_stack.1.feed_forward.layer_norm.weight                  [1024]
encoder.layer_stack.1.feed_forward.layer_norm.bias                    [1024]
encoder.layer_stack.2.self_attention.attention.q_transform.weight    [1024, 1024]
encoder.layer_stack.2.self_attention.attention.q_transform.bias          [1024]
encoder.layer_stack.2.self_attention.attention.k_transform.weight    [1024, 1024]
encoder.layer_stack.2.self_attention.attention.k_transform.bias          [1024]
encoder.layer_stack.2.self_attention.attention.v_transform.weight    [1024, 1024]
encoder.layer_stack.2.self_attention.attention.v_transform.bias          [1024]
encoder.layer_stack.2.self_attention.attention.o_transform.weight    [1024, 1024]
encoder.layer_stack.2.self_attention.attention.o_transform.bias          [1024]
encoder.layer_stack.2.self_attention.layer_norm.weight                [1024]
encoder.layer_stack.2.self_attention.layer_norm.bias                  [1024]
encoder.layer_stack.2.feed_forward.ffn_layer.input_transform.weight    [8192, 1024]
encoder.layer_stack.2.feed_forward.ffn_layer.input_transform.bias          [8192]
encoder.layer_stack.2.feed_forward.ffn_layer.output_transform.weight    [1024, 8192]
encoder.layer_stack.2.feed_forward.ffn_layer.output_transform.bias          [1024]
encoder.layer_stack.2.feed_forward.layer_norm.weight                  [1024]
encoder.layer_stack.2.feed_forward.layer_norm.bias                    [1024]
encoder.layer_stack.3.self_attention.attention.q_transform.weight    [1024, 1024]
encoder.layer_stack.3.self_attention.attention.q_transform.bias          [1024]
encoder.layer_stack.3.self_attention.attention.k_transform.weight    [1024, 1024]
encoder.layer_stack.3.self_attention.attention.k_transform.bias          [1024]
encoder.layer_stack.3.self_attention.attention.v_transform.weight    [1024, 1024]
encoder.layer_stack.3.self_attention.attention.v_transform.bias          [1024]
encoder.layer_stack.3.self_attention.attention.o_transform.weight    [1024, 1024]
encoder.layer_stack.3.self_attention.attention.o_transform.bias          [1024]
encoder.layer_stack.3.self_attention.layer_norm.weight                [1024]
encoder.layer_stack.3.self_attention.layer_norm.bias                  [1024]
encoder.layer_stack.3.feed_forward.ffn_layer.input_transform.weight    [8192, 1024]
encoder.layer_stack.3.feed_forward.ffn_layer.input_transform.bias          [8192]
encoder.layer_stack.3.feed_forward.ffn_layer.output_transform.weight    [1024, 8192]
encoder.layer_stack.3.feed_forward.ffn_layer.output_transform.bias          [1024]
encoder.layer_stack.3.feed_forward.layer_norm.weight                  [1024]
encoder.layer_stack.3.feed_forward.layer_norm.bias                    [1024]
encoder.layer_stack.4.self_attention.attention.q_transform.weight    [1024, 1024]
encoder.layer_stack.4.self_attention.attention.q_transform.bias          [1024]
encoder.layer_stack.4.self_attention.attention.k_transform.weight    [1024, 1024]
encoder.layer_stack.4.self_attention.attention.k_transform.bias          [1024]
encoder.layer_stack.4.self_attention.attention.v_transform.weight    [1024, 1024]
encoder.layer_stack.4.self_attention.attention.v_transform.bias          [1024]
encoder.layer_stack.4.self_attention.attention.o_transform.weight    [1024, 1024]
encoder.layer_stack.4.self_attention.attention.o_transform.bias          [1024]
encoder.layer_stack.4.self_attention.layer_norm.weight                [1024]
encoder.layer_stack.4.self_attention.layer_norm.bias                  [1024]
encoder.layer_stack.4.feed_forward.ffn_layer.input_transform.weight    [8192, 1024]
encoder.layer_stack.4.feed_forward.ffn_layer.input_transform.bias          [8192]
encoder.layer_stack.4.feed_forward.ffn_layer.output_transform.weight    [1024, 8192]
encoder.layer_stack.4.feed_forward.ffn_layer.output_transform.bias          [1024]
encoder.layer_stack.4.feed_forward.layer_norm.weight                  [1024]
encoder.layer_stack.4.feed_forward.layer_norm.bias                    [1024]
encoder.layer_stack.5.self_attention.attention.q_transform.weight    [1024, 1024]
encoder.layer_stack.5.self_attention.attention.q_transform.bias          [1024]
encoder.layer_stack.5.self_attention.attention.k_transform.weight    [1024, 1024]
encoder.layer_stack.5.self_attention.attention.k_transform.bias          [1024]
encoder.layer_stack.5.self_attention.attention.v_transform.weight    [1024, 1024]
encoder.layer_stack.5.self_attention.attention.v_transform.bias          [1024]
encoder.layer_stack.5.self_attention.attention.o_transform.weight    [1024, 1024]
encoder.layer_stack.5.self_attention.attention.o_transform.bias          [1024]
encoder.layer_stack.5.self_attention.layer_norm.weight                [1024]
encoder.layer_stack.5.self_attention.layer_norm.bias                  [1024]
encoder.layer_stack.5.feed_forward.ffn_layer.input_transform.weight    [8192, 1024]
encoder.layer_stack.5.feed_forward.ffn_layer.input_transform.bias          [8192]
encoder.layer_stack.5.feed_forward.ffn_layer.output_transform.weight    [1024, 8192]
encoder.layer_stack.5.feed_forward.ffn_layer.output_transform.bias          [1024]
encoder.layer_stack.5.feed_forward.layer_norm.weight                  [1024]
encoder.layer_stack.5.feed_forward.layer_norm.bias                    [1024]
decoder.layer_stack.0.self_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.0.self_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.0.self_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.0.self_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.0.self_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.0.self_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.0.self_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.0.self_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.0.self_attention.layer_norm.weight                [1024]
decoder.layer_stack.0.self_attention.layer_norm.bias                  [1024]
decoder.layer_stack.0.encdec_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.0.encdec_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.0.encdec_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.0.encdec_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.0.encdec_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.0.encdec_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.0.encdec_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.0.encdec_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.0.encdec_attention.layer_norm.weight              [1024]
decoder.layer_stack.0.encdec_attention.layer_norm.bias                [1024]
decoder.layer_stack.0.feed_forward.ffn_layer.input_transform.weight    [4096, 1024]
decoder.layer_stack.0.feed_forward.ffn_layer.input_transform.bias          [4096]
decoder.layer_stack.0.feed_forward.ffn_layer.output_transform.weight    [1024, 4096]
decoder.layer_stack.0.feed_forward.ffn_layer.output_transform.bias          [1024]
decoder.layer_stack.0.feed_forward.layer_norm.weight                  [1024]
decoder.layer_stack.0.feed_forward.layer_norm.bias                    [1024]
decoder.layer_stack.1.self_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.1.self_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.1.self_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.1.self_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.1.self_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.1.self_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.1.self_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.1.self_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.1.self_attention.layer_norm.weight                [1024]
decoder.layer_stack.1.self_attention.layer_norm.bias                  [1024]
decoder.layer_stack.1.encdec_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.1.encdec_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.1.encdec_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.1.encdec_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.1.encdec_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.1.encdec_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.1.encdec_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.1.encdec_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.1.encdec_attention.layer_norm.weight              [1024]
decoder.layer_stack.1.encdec_attention.layer_norm.bias                [1024]
decoder.layer_stack.1.feed_forward.ffn_layer.input_transform.weight    [4096, 1024]
decoder.layer_stack.1.feed_forward.ffn_layer.input_transform.bias          [4096]
decoder.layer_stack.1.feed_forward.ffn_layer.output_transform.weight    [1024, 4096]
decoder.layer_stack.1.feed_forward.ffn_layer.output_transform.bias          [1024]
decoder.layer_stack.1.feed_forward.layer_norm.weight                  [1024]
decoder.layer_stack.1.feed_forward.layer_norm.bias                    [1024]
decoder.layer_stack.2.self_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.2.self_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.2.self_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.2.self_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.2.self_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.2.self_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.2.self_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.2.self_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.2.self_attention.layer_norm.weight                [1024]
decoder.layer_stack.2.self_attention.layer_norm.bias                  [1024]
decoder.layer_stack.2.encdec_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.2.encdec_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.2.encdec_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.2.encdec_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.2.encdec_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.2.encdec_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.2.encdec_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.2.encdec_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.2.encdec_attention.layer_norm.weight              [1024]
decoder.layer_stack.2.encdec_attention.layer_norm.bias                [1024]
decoder.layer_stack.2.feed_forward.ffn_layer.input_transform.weight    [4096, 1024]
decoder.layer_stack.2.feed_forward.ffn_layer.input_transform.bias          [4096]
decoder.layer_stack.2.feed_forward.ffn_layer.output_transform.weight    [1024, 4096]
decoder.layer_stack.2.feed_forward.ffn_layer.output_transform.bias          [1024]
decoder.layer_stack.2.feed_forward.layer_norm.weight                  [1024]
decoder.layer_stack.2.feed_forward.layer_norm.bias                    [1024]
decoder.layer_stack.3.self_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.3.self_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.3.self_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.3.self_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.3.self_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.3.self_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.3.self_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.3.self_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.3.self_attention.layer_norm.weight                [1024]
decoder.layer_stack.3.self_attention.layer_norm.bias                  [1024]
decoder.layer_stack.3.encdec_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.3.encdec_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.3.encdec_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.3.encdec_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.3.encdec_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.3.encdec_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.3.encdec_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.3.encdec_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.3.encdec_attention.layer_norm.weight              [1024]
decoder.layer_stack.3.encdec_attention.layer_norm.bias                [1024]
decoder.layer_stack.3.feed_forward.ffn_layer.input_transform.weight    [4096, 1024]
decoder.layer_stack.3.feed_forward.ffn_layer.input_transform.bias          [4096]
decoder.layer_stack.3.feed_forward.ffn_layer.output_transform.weight    [1024, 4096]
decoder.layer_stack.3.feed_forward.ffn_layer.output_transform.bias          [1024]
decoder.layer_stack.3.feed_forward.layer_norm.weight                  [1024]
decoder.layer_stack.3.feed_forward.layer_norm.bias                    [1024]
decoder.layer_stack.4.self_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.4.self_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.4.self_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.4.self_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.4.self_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.4.self_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.4.self_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.4.self_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.4.self_attention.layer_norm.weight                [1024]
decoder.layer_stack.4.self_attention.layer_norm.bias                  [1024]
decoder.layer_stack.4.encdec_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.4.encdec_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.4.encdec_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.4.encdec_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.4.encdec_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.4.encdec_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.4.encdec_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.4.encdec_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.4.encdec_attention.layer_norm.weight              [1024]
decoder.layer_stack.4.encdec_attention.layer_norm.bias                [1024]
decoder.layer_stack.4.feed_forward.ffn_layer.input_transform.weight    [4096, 1024]
decoder.layer_stack.4.feed_forward.ffn_layer.input_transform.bias          [4096]
decoder.layer_stack.4.feed_forward.ffn_layer.output_transform.weight    [1024, 4096]
decoder.layer_stack.4.feed_forward.ffn_layer.output_transform.bias          [1024]
decoder.layer_stack.4.feed_forward.layer_norm.weight                  [1024]
decoder.layer_stack.4.feed_forward.layer_norm.bias                    [1024]
decoder.layer_stack.5.self_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.5.self_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.5.self_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.5.self_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.5.self_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.5.self_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.5.self_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.5.self_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.5.self_attention.layer_norm.weight                [1024]
decoder.layer_stack.5.self_attention.layer_norm.bias                  [1024]
decoder.layer_stack.5.encdec_attention.attention.q_transform.weight    [1024, 1024]
decoder.layer_stack.5.encdec_attention.attention.q_transform.bias          [1024]
decoder.layer_stack.5.encdec_attention.attention.k_transform.weight    [1024, 1024]
decoder.layer_stack.5.encdec_attention.attention.k_transform.bias          [1024]
decoder.layer_stack.5.encdec_attention.attention.v_transform.weight    [1024, 1024]
decoder.layer_stack.5.encdec_attention.attention.v_transform.bias          [1024]
decoder.layer_stack.5.encdec_attention.attention.o_transform.weight    [1024, 1024]
decoder.layer_stack.5.encdec_attention.attention.o_transform.bias          [1024]
decoder.layer_stack.5.encdec_attention.layer_norm.weight              [1024]
decoder.layer_stack.5.encdec_attention.layer_norm.bias                [1024]
decoder.layer_stack.5.feed_forward.ffn_layer.input_transform.weight    [4096, 1024]
decoder.layer_stack.5.feed_forward.ffn_layer.input_transform.bias          [4096]
decoder.layer_stack.5.feed_forward.ffn_layer.output_transform.weight    [1024, 4096]
decoder.layer_stack.5.feed_forward.ffn_layer.output_transform.bias          [1024]
decoder.layer_stack.5.feed_forward.layer_norm.weight                  [1024]
decoder.layer_stack.5.feed_forward.layer_norm.bias                    [1024]