{
    "configurations": [
        {
            "name": "Python: sknn-inference",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {
                "CUDA_VISIBLE_DEVICES" : "2",
            },
            "args": ["/data/dirkiedye/knn-mt-research/data-bin/it-test-pad-1",
            "--gen-subset", "test", 
            "--path", "/data/dirkiedye/knn-mt-research/pretrain/wmt19_pretrain/wmt19.de-en.ffn8192.pt", 
            "--arch", "transformer_wmt19_de_en_with_datastore", 
            "--task", "translation_tm", 
            "--beam", "4", 
            "--lenpen", "0.6", 
            "--max-len-a", "1.2", 
            "--max-len-b", "10", 
            "--source-lang", "de", 
            "--target-lang","en",
            "--scoring", "sacrebleu", 
            "--quiet",
            "--batch-size", "16", 
            "--tm-counts", "8",
            "--tokenizer", "moses", 
            "--remove-bpe",
            "--model-overrides","{\"use_knn_datastore\": True, \"use_faiss_to_search\": False, \"dstore_size\": 10000, \"dstore_fp16\": True, \"k\": 8, \"probe\": 32,\"knn_sim_func\":\"do_not_recomp_l2\", \"use_gpu_to_search\": True, \"move_dstore_to_mem\": True, \"no_load_keys\":True, \"knn_temperature_type\":\"fix\", \"knn_temperature_value\":100, \"knn_lambda_temperature_value\":100 }",

            ]
        },

        {
            "name": "Python: nmt-inference",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": ["/data/dirkiedye/knn-mt-research/data-bin/it",
            "--gen-subset", "test", 
            "--path", "/data/dirkiedye/knn-mt-research/pretrain/wmt19_pretrain/wmt19.de-en.ffn8192.pt", 
            "--arch", "transformer", 
            "--task", "translation", 
            "--beam", "4", 
            "--lenpen", "0.6", 
            "--max-len-a", "1.2", 
            "--max-len-b", "10", 
            "--source-lang", "de", 
            "--target-lang","en",
            "--scoring", "sacrebleu", 
            "--quiet",
            "--batch-size", "4", 
            "--tokenizer", "moses", 
            "--remove-bpe",
            ]
        }, 

        {
            "name": "Python: aknn-inference",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": ["/data/dirkiedye/knn-mt-research/data-bin/it",
            "--gen-subset", "test", 
            "--path", "/data/dirkiedye/knn-mt-research/pretrain/wmt19_pretrain/wmt19.de-en.ffn8192.pt", 
            "--arch", "transformer_wmt19_de_en_with_datastore", 
            "--task", "translation", 
            "--beam", "4", 
            "--lenpen", "0.6", 
            "--max-len-a", "1.2", 
            "--max-len-b", "10", 
            "--source-lang", "de", 
            "--target-lang","en",
            "--scoring", "sacrebleu", 
            "--quiet",
            "--batch-size", "4", 
            "--tokenizer", "moses", 
            "--remove-bpe",
            "--model-overrides","{\"load_knn_datastore\": True, \"use_knn_datastore\": True, \"dstore_fp16\": True, \"k\": 16, \"probe\": 32,\"knn_sim_func\":\"do_not_recomp_l2\", \"use_gpu_to_search\": True, \"move_dstore_to_mem\": True, \"no_load_keys\":True, \"knn_temperature_type\":\"fix\", \"knn_temperature_value\":200 }",
            ]
        }, 
    ]
}
